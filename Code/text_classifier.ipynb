{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying YouTube Comments using Supervised Learning\n",
    "In this notebook, we will use supervised learning techniques to classify YouTube comments. The goal is to categorize comments into different classes such as positive, negative etc. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os \n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from _functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO : Update this file to pull in all data at once\n",
    "Import the data as a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "Clean the data to remove empty rows, row[0] containing the raw data to put the text into a form such that it is ready for BERT imput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5146, 1)\n"
     ]
    }
   ],
   "source": [
    "# Import the data as dataframe\n",
    "data_concat = pd.DataFrame(columns=[\"comment\"])\n",
    "\n",
    "\n",
    "current_dir = Path.cwd().parent\n",
    "\n",
    "data_path = current_dir / \"Data\" / \"RawData\" \n",
    "\n",
    "for file_name in os.listdir(data_path):\n",
    "\n",
    "    # Declare the file path\n",
    "    file_path = data_path / file_name\n",
    "\n",
    "    # Import the data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    clean_comments = clean_data(df).to_frame()\n",
    "    \n",
    "    data_concat = pd.concat([data_concat, clean_comments])\n",
    "\n",
    "print(data_concat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potentially translate here? \n",
    "Quite a few non-English comments, may be worth trying a translator. However, if it is too computationally expensive on time and memory, just drop the comments here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use VADER HERE\n",
    "Vader is to be used for sentiment analysis at this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use secondary classification for country/target  \n",
    "Potentially use targeted BERT model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use secondary classification for Individual involved  \n",
    "Potentially use targeted BERT model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
